{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcc59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "class PairedImageDataset(Dataset):\n",
    "    def __init__(self, input_dir, target_dir, transform=None):\n",
    "        self.input_dir = Path(input_dir)\n",
    "        self.target_dir = Path(target_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Match files by name\n",
    "        self.input_files = sorted(self.input_dir.glob(\"*\"))\n",
    "        self.target_files = sorted(self.target_dir.glob(\"*\"))\n",
    "    def __len__(self):\n",
    "        return len(self.input_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_img = Image.open(self.input_files[idx])\n",
    "        target_img = Image.open(self.target_files[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            input_img = self.transform(input_img)\n",
    "            target_img = self.transform(target_img)\n",
    "\n",
    "        return input_img, target_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe21c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentTransforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "trainingData = PairedImageDataset(input_dir=r\"O:/Data upscale train/Dataset/train/input/_upscaleFactor2/\", target_dir=r\"O:/Data upscale train/Dataset/train/target/_upscaleFactor2/\", transform=currentTransforms)\n",
    "trainingLoader = DataLoader(trainingData, batch_size=1, shuffle=True)\n",
    "\n",
    "validationData = PairedImageDataset(input_dir=r\"O:/Data upscale train/Dataset/validate/input/_upscaleFactor2/\", target_dir=r\"O:/Data upscale train/Dataset/validate/target/_upscaleFactor2/\", transform=currentTransforms)\n",
    "validationLoader = DataLoader(validationData, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b890cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class upscaleModel(nn.Module):\n",
    "    def __init__(self, upscale_factor=2):\n",
    "        super(upscaleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(32, 1 * (upscale_factor ** 2), (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = F.sigmoid(self.pixel_shuffle(self.conv3(x)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be8ddf",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2a669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Train Loss: 0.06598141962879864, Val Loss: 0.2595246464101707\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "# Pick GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Move your model to the device\n",
    "model = upscaleModel(upscale_factor=2).to(device)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "train_loss, validation_loss = [], []\n",
    "num_epoch = 300\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    run_loss = 0.0\n",
    "    model.train()\n",
    "    for input, target in trainingLoader:\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        forwardOut = model(input)\n",
    "        #handle dimension mismatch before calculating MSE\n",
    "        out_h, out_w = forwardOut.shape[2], forwardOut.shape[3]\n",
    "        tgt_h, tgt_w = target.shape[2], target.shape[3]\n",
    "\n",
    "        min_h = min(out_h, tgt_h)\n",
    "        min_w = min(out_w, tgt_w)\n",
    "\n",
    "        forwardOut = forwardOut[:, :, :min_h, :min_w]\n",
    "        target     = target[:, :, :min_h, :min_w]\n",
    "        #now calc loss\n",
    "        MSE = loss(forwardOut, target)\n",
    "        #backpropagate\n",
    "        MSE.backward()\n",
    "        optimizer.step()\n",
    "        run_loss += MSE.item()\n",
    "    \n",
    "    train_loss.append(run_loss/len(trainingLoader.dataset))\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for input, target in validationLoader:\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            forwardOut = model(input)\n",
    "            #handle dimension mismatch\n",
    "            out_h, out_w = forwardOut.shape[2], forwardOut.shape[3]\n",
    "            tgt_h, tgt_w = target.shape[2], target.shape[3]\n",
    "\n",
    "            min_h = min(out_h, tgt_h)\n",
    "            min_w = min(out_w, tgt_w)\n",
    "\n",
    "            forwardOut = forwardOut[:, :, :min_h, :min_w]\n",
    "            target     = target[:, :, :min_h, :min_w]\n",
    "            MSE = loss(forwardOut, target)\n",
    "            run_loss += MSE.item()\n",
    "    validation_loss.append(run_loss/len(validationLoader.dataset))\n",
    "    scheduler.step(validation_loss[-1])\n",
    "    print(f\"Epoch {epoch+1}/{num_epoch}, Train Loss: {train_loss[epoch]}, Val Loss: {validation_loss[epoch]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57eb0ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 850, 846])\n",
      "torch.Size([1, 1, 850, 845])\n"
     ]
    }
   ],
   "source": [
    "print(forwardOut.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff5019fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 850, 845])\n",
      "torch.Size([1, 1, 850, 845])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out_h, out_w = forwardOut.shape[2], forwardOut.shape[3]\n",
    "tgt_h, tgt_w = target.shape[2], target.shape[3]\n",
    "\n",
    "min_h = min(out_h, tgt_h)\n",
    "min_w = min(out_w, tgt_w)\n",
    "\n",
    "forwardOut = forwardOut[:, :, :min_h, :min_w]\n",
    "target     = target[:, :, :min_h, :min_w]\n",
    "\n",
    "print(forwardOut.shape)\n",
    "print(target.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coarseGrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bcc59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "class PairedImageDataset(Dataset):\n",
    "    def __init__(self, input_dir, target_dir, transform=None):\n",
    "        self.input_dir = Path(input_dir)\n",
    "        self.target_dir = Path(target_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Match files by name\n",
    "        self.input_files = sorted(self.input_dir.glob(\"*\"))\n",
    "        self.target_files = sorted(self.target_dir.glob(\"*\"))\n",
    "    def __len__(self):\n",
    "        return len(self.input_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_img = Image.open(self.input_files[idx])\n",
    "        target_img = Image.open(self.target_files[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            input_img = self.transform(input_img)\n",
    "            target_img = self.transform(target_img)\n",
    "\n",
    "        return input_img, target_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fe21c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentTransforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "trainingData = PairedImageDataset(input_dir=r\"O:/Data upscale train/Dataset/train/input/_upscaleFactor2/\", target_dir=r\"O:/Data upscale train/Dataset/train/target/_upscaleFactor2/\", transform=currentTransforms)\n",
    "trainingLoader = DataLoader(trainingData, batch_size=1, shuffle=True)\n",
    "\n",
    "validationData = PairedImageDataset(input_dir=r\"O:/Data upscale train/Dataset/validate/input/_upscaleFactor2/\", target_dir=r\"O:/Data upscale train/Dataset/validate/target/_upscaleFactor2/\", transform=currentTransforms)\n",
    "validationLoader = DataLoader(validationData, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60b890cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class upscaleModel(nn.Module):\n",
    "    def __init__(self, upscale_factor=2):\n",
    "        super(upscaleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(32, 1 * (upscale_factor ** 2), (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        x = F.tanh(self.conv2(x))\n",
    "        x = F.sigmoid(self.pixel_shuffle(self.conv3(x)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be8ddf",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import cv2 as cv\n",
    "\n",
    "#create instance\n",
    "Net = upscaleModel(upscale_factor=2)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr=0.001)\n",
    "\n",
    "train_loss, val_loss = [], []\n",
    "num_epoch = 10\n",
    "\n",
    "# Pick GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Move your model to the device\n",
    "Net.to(device)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    run_loss = 0.0\n",
    "    Net.train()\n",
    "    for input, target in trainingLoader:\n",
    "        optimizer.zero_grad()\n",
    "        forwardOut = Net(input.to(device))\n",
    "        #handle dimension mismatch before calculating MSE\n",
    "        outDim = forwardOut.cpu().detach().numpy().shape[2:] \n",
    "        targetDim = target.cpu().detach().numpy().shape[2:]\n",
    "        diff1 = outDim[0] - targetDim[0]\n",
    "        diff2 = outDim[1] - targetDim[1]\n",
    "        if diff1 > 0:\n",
    "            forwardOut = forwardOut[:, :, :targetDim[0], :]\n",
    "        if diff2 > 0:\n",
    "            forwardOut = forwardOut[:, :, :, :targetDim[1]]\n",
    "        if diff1 < 0:\n",
    "            target = target[:, :, :outDim[0], :]\n",
    "        if diff2 < 0:\n",
    "            target = target[:, :, :, :outDim[1]]\n",
    "\n",
    "        #now calc loss\n",
    "        MSE = loss(forwardOut, target.to(device))\n",
    "\n",
    "        MSE.backward()\n",
    "        optimizer.step()\n",
    "        run_loss = MSE.item()\n",
    "\n",
    "    train_loss.append(run_loss/len(trainingLoader.input_files))\n",
    "    Net.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for input, target in validationLoader:\n",
    "            forwardOut = Net(input.to(device))\n",
    "            MSE = loss(forwardOut, target.to(device))\n",
    "            run_loss += MSE.item()\n",
    "    val_loss.append(run_loss/len(validationLoader.input_files))\n",
    "    print(f\"Epoch {epoch+1}/{num_epoch}, Train Loss: {train_loss}, Val Loss: {val_loss}\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff5019fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 922, 1446)\n",
      "(921, 1445)\n"
     ]
    }
   ],
   "source": [
    "print(forwardOut.cpu().detach().numpy().shape )\n",
    "\n",
    "print(target.cpu().detach().numpy().shape[2:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coarseGrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
